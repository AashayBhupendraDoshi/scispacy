import pytest

from scispacy.custom_sentence_segmenter import merge_segments

TEST_CASES = [
              ("LSTM networks, which we preview in Sec. 2, have been successfully", ["LSTM networks, which we preview in Sec. 2, have been successfully"]),
              ("When the tree is simply a chain, both Eqs. 2–8 and Eqs. 9–14 reduce to the standard LSTM transitions, Eqs. 1.", ["When the tree is simply a chain, both Eqs. 2–8 and Eqs. 9–14 reduce to the standard LSTM transitions, Eqs. 1."]),
              ("We used fluorescence time-lapse microscopy (Fig. 1D; fig. S1 and movies S1 and S2) and computational", ["We used fluorescence time-lapse microscopy (Fig. 1D; fig. S1 and movies S1 and S2) and computational"]),
              ("Hill functions indeed fit the data well (Fig. 3A and Table 1).", ["Hill functions indeed fit the data well (Fig. 3A and Table 1)."]),
              ('In order to produce sentence representations that fully capture the semantics of natural language, order-insensitive models are insufficient due to their inability to account for differences in meaning as a result of differences in word order or syntactic structure (e.g., “cats climb trees” vs. “trees climb cats”).', ['In order to produce sentence representations that fully capture the semantics of natural language, order-insensitive models are insufficient due to their inability to account for differences in meaning as a result of differences in word order or syntactic structure (e.g., “cats climb trees” vs. “trees climb cats”).']),
              ("There is an average exact sparsity (fraction of zeros) of the hidden layers of 83.40% on MNIST and 72.00% on CIFAR10. Figure 3 (left) provides a better understanding of the influence of sparsity.", ["There is an average exact sparsity (fraction of zeros) of the hidden layers of 83.40% on MNIST and 72.00% on CIFAR10.", "Figure 3 (left) provides a better understanding of the influence of sparsity."]),
              ("Sparsity has become a concept of interest, not only in computational neuroscience and machine learning but also in statistics and signal processing (Candes and Tao, 2005). It was first introduced in computational neuroscience in the context of sparse coding in the visual system (Olshausen and Field, 1997).", ["Sparsity has become a concept of interest, not only in computational neuroscience and machine learning but also in statistics and signal processing (Candes and Tao, 2005).", "It was first introduced in computational neuroscience in the context of sparse coding in the visual system (Olshausen and Field, 1997)."]),
              ("1) The first item. 2) The second item.", ["1) The first item.", "2) The second item."]),
              ("two of these stages (in areas V1 and V2 of visual cortex) (Lee et al., 2008), and that they", ["two of these stages (in areas V1 and V2 of visual cortex) (Lee et al., 2008), and that they"]),
              ("all neu-\nrons fire at", ["all neu-\nrons fire at"]),
              ("the support of the Defense Advanced Resarch Projects Agency (DARPA) Deep Exploration and Filtering of Text (DEFT) Program under Air Force Research Laboratory (AFRL) contract", ["the support of the Defense Advanced Resarch Projects Agency (DARPA) Deep Exploration and Filtering of Text (DEFT) Program under Air Force Research Laboratory (AFRL) contract"]),
              ("While proprietary environments such as Microsoft Robotics Studio [9] and Webots [10] have many commendable attributes, we feel there is no substitute for a fully open platform.", ["While proprietary environments such as Microsoft Robotics Studio [9] and Webots [10] have many commendable attributes, we feel there is no substitute for a fully open platform."]),
              ("We first produce sentence representations hL and hR for each sentence in the pair using a Tree-LSTM model over each sentence’s parse tree.", ["We first produce sentence representations hL and hR for each sentence in the pair using a Tree-LSTM model over each sentence’s parse tree."]),
              ("LSTM networks, which we review in Sec. 2, have been successfully applied to a variety of sequence modeling and prediction tasks, notably machine translation (Bahdanau et al., 2014; Sutskever et al., 2014), speech recognition (Graves et al., 2013), image caption generation (Vinyals et al., 2014), and program execution (Zaremba and Sutskever, 2014).", ["LSTM networks, which we review in Sec. 2, have been successfully applied to a variety of sequence modeling and prediction tasks, notably machine translation (Bahdanau et al., 2014; Sutskever et al., 2014), speech recognition (Graves et al., 2013), image caption generation (Vinyals et al., 2014), and program execution (Zaremba and Sutskever, 2014)."]),
              ("1 Introduction\n\nMost models for distributed representations of phrases and sentences—that is, models where realvalued vectors are used to represent meaning—fall into one of three classes: bag-of-words models, sequence models, and tree-structured models.", ["1 Introduction\n\n", "Most models for distributed representations of phrases and sentences—that is, models where realvalued vectors are used to represent meaning—fall into one of three classes: bag-of-words models, sequence models, and tree-structured models."]),
              ("In this section, we will elaborate these philosophies and shows how they influenced the design and implementation of ROS.\n\nA. Peer-to-Peer\n\nA system built using ROS consists of a number of processes, potentially on a number of different", ["In this section, we will elaborate these philosophies and shows how they influenced the design and implementation of ROS.\n\n", "A. Peer-to-Peer\n\n", "A system built using ROS consists of a number of processes, potentially on a number of different"]),
              ("\n\n2 Long Short-Term Memory Networks\n\n\n\n2.1 Overview\n\nRecurrent neural networks (RNNs) are able to process input sequences of arbitrary length via the recursive application of a transition function on a hidden state vector ht.", ["\n\n2 Long Short-Term Memory Networks\n\n\n\n", "2.1 Overview\n\n", "Recurrent neural networks (RNNs) are able to process input sequences of arbitrary length via the recursive application of a transition function on a hidden state vector ht."]),
              ("In order to address all three aspects, it is necessary to observe gene regulation in individual cells over time. Therefore, we built Bl-cascade[ strains of Escherichia coli, containing the l repressor and a downstream gene, such that both the amount of the repressor protein and the rate of expression of its target gene could be monitored simultaneously in individual cells (Fig. 1B). These strains incorporate a yellow fluorescent repressor fusion protein (cI-yfp) and a chromosomally integrated target promoter (P R ) controlling cyan fluorescent protein (cfp).", ["In order to address all three aspects, it is necessary to observe gene regulation in individual cells over time.", "Therefore, we built Bl-cascade[ strains of Escherichia coli, containing the l repressor and a downstream gene, such that both the amount of the repressor protein and the rate of expression of its target gene could be monitored simultaneously in individual cells (Fig. 1B).", "These strains incorporate a yellow fluorescent repressor fusion protein (cI-yfp) and a chromosomally integrated target promoter (P R ) controlling cyan fluorescent protein (cfp)."]),
              ("This is a sentence. (This is an interjected sentence.) This is also a sentence.", ["This is a sentence.", "(This is an interjected sentence.)", "This is also a sentence."]),
              pytest.param("Thus, we first compute EMC 3 's response time-i.e., the duration from the initial of a call (from/to a participant in the target region) to the time when the decision of task assignment is made; and then, based on the computed response time, we estimate EMC 3 maximum throughput [28]-i.e., the maximum number of mobile users allowed in the MCS system. EMC 3 algorithm is implemented with the Java SE platform and is running on a Java HotSpot(TM) 64-Bit Server VM; and the implementation details are given in Appendix, available in the online supplemental material.", ["Thus, we first compute EMC 3 's response time-i.e., the duration from the initial of a call (from/to a participant in the target region) to the time when the decision of task assignment is made; and then, based on the computed response time, we estimate EMC 3 maximum throughput [28]-i.e., the maximum number of mobile users allowed in the MCS system.", "EMC 3 algorithm is implemented with the Java SE platform and is running on a Java HotSpot(TM) 64-Bit Server VM; and the implementation details are given in Appendix, available in the online supplemental material."], marks=pytest.mark.xfail),
              ("Random walk models (Skellam, 1951;Turchin, 1998) received a lot of attention and were then extended to several more mathematically and statistically sophisticated approaches to interpret movement data such as State-Space Models (SSM) (Jonsen et al., 2003(Jonsen et al., , 2005 and Brownian Bridge Movement Model (BBMM) (Horne et al., 2007). Nevertheless, these models require heavy computational resources (Patterson et al., 2008) and unrealistic structural a priori hypotheses about movement, such as homogeneous movement behavior. A fundamental property of animal movements is behavioral heterogeneity (Gurarie et al., 2009) and these models poorly performed in highlighting behavioral changes in animal movements through space and time (Kranstauber et al., 2012).", ["Random walk models (Skellam, 1951;Turchin, 1998) received a lot of attention and were then extended to several more mathematically and statistically sophisticated approaches to interpret movement data such as State-Space Models (SSM) (Jonsen et al., 2003(Jonsen et al., , 2005 and Brownian Bridge Movement Model (BBMM) (Horne et al., 2007).", "Nevertheless, these models require heavy computational resources (Patterson et al., 2008) and unrealistic structural a priori hypotheses about movement, such as homogeneous movement behavior.", "A fundamental property of animal movements is behavioral heterogeneity (Gurarie et al., 2009) and these models poorly performed in highlighting behavioral changes in animal movements through space and time (Kranstauber et al., 2012)."]),
              ('. . .', ['. . .']),
              pytest.param("IF condition and goalCondition THEN action condition relates to the current state and goalCondition to the goal state. If variable bindings exist such that predicates in condition match with the current state, and predicates in goalCondition match with the goal state then the action may be performed. Note that the action's precondition as specified in the domain model must also be satisfied. Figure 5 presents an outline of the system. Each iteration starts with a population of policies (line(2)). Current L2Plan settings are such that the individuals comprising the (1) Create initial population (2) WHILE termination criterion false (3) Determine n% fittest polices (4) Perform local search on policies (5) Insert improved policies in new generation (6) WHILE new generation not full (7) SET Pol to empty policy (8) Select two parents (9) IF crossover (10) Perform crossover (11) Pol := fittest of parents & offspring (12) ELSE (13) Pol := fittest of parents (14) ENDIF (15) IF mutation (16) Perform mutation on Pol (17) ENDIF (18) Perform local search on Pol (19) Insert Pol in new generation (20) ENDWHILE (21) (5)). Note that the evaluation of policies is implied when the fittest policy or policies is/are required.", ['IF condition and goalCondition THEN action condition relates to the current state and goalCondition to the goal state.', 'If variable bindings exist such that predicates in condition match with the current state, and predicates in goalCondition match with the goal state then the action may be performed.', "Note that the action's precondition as specified in the domain model must also be satisfied.", 'Figure 5 presents an outline of the system.', 'Each iteration starts with a population of policies (line(2)).', 'Current L2Plan settings are such that the individuals comprising the (1) Create initial population (2) WHILE termination criterion false (3) Determine n% fittest polices (4) Perform local search on policies (5) Insert improved policies in new generation (6) WHILE new generation not full (7) SET Pol to empty policy (8) Select two parents (9) IF crossover (1) Perform crossover (1) Pol := fittest of parents & offspring (1) ELSE (1) Pol := fittest of parents (1) ENDIF (1) IF mutation (1) Perform mutation on Pol (1) ENDIF (1) Perform local search on Pol (1) Insert Pol in new generation (2) ENDWHILE (2) (5)).', 'Note that the evaluation of policies is implied when the fittest policy or policies is/are required.'], marks=pytest.mark.xfail)
             ]

@pytest.mark.parametrize('text,expected_sents', TEST_CASES)
def test_custom_segmentation(en_with_combined_rule_tokenizer_and_segmenter_fixture, remove_new_lines_fixture, text, expected_sents):
    doc = en_with_combined_rule_tokenizer_and_segmenter_fixture(text)
    sents = [s.text for s in doc.sents]
    assert sents == expected_sents

def test_segmenter(en_with_combined_rule_tokenizer_and_segmenter_fixture):
    # this text crashes pysbd
    text = "Then, (S\{ℓ 1 , ℓ 2 }) ∪ {v} is a smaller power dominating set than S, which is a contradiction. Now consider the case in which v ∈ V is incident to exactly two leaves, ℓ 1 and ℓ 2 , and suppose there is a minimum power dominating set S of G such that {v, ℓ 1 , ℓ 2 } ∩ S = ∅."
    doc = en_with_combined_rule_tokenizer_and_segmenter_fixture(text)
    # this is really just testing that we handle the case where pysbd crashes
    assert len(list(doc.sents)) > 0

    # this text crashes pysbd
    text = "Note that by definition of J, for i ∈ J, S i can be chosen such that S i \{v} is a set realizing γ P (T i ). By Lemma 3.8, for i ∈ I ′ , S i can be chosen such that v does not need to perform a force. Suppose first that |I| ≤ 1 and |J| ≥ 1; we claim that k i=1 (S i \{v}) is a power dominating set of T . To see why, note that for each i ∈ J, the set S i \{v} will force all of V (T i ) in T , including v. Then for i ∈ I ′ , all components T i can be forced by the sets S i \{v}, i ∈ I ′ , since v is colored but does not need to perform a force in those components. Finally, if there is a component T i * , i * ∈ I, v will have a single uncolored neighbor at this step of the forcing process (which is in T i * ), and it can force this neighbor; since v is a leaf in T i * , this is the same as dominating its neighbor. Thus, S i * \{v} can power dominate T i * after all other components are colored."
    doc = en_with_combined_rule_tokenizer_and_segmenter_fixture(text)
    # this is really just testing that we handle the case where pysbd crashes
    assert len(list(doc.sents)) > 0

def test_merge_segment():
    segments = ["This sentence mentions Eqs.", "1-4 and should not be split."]
    merged_segments = merge_segments(segments)
    assert len(merged_segments) == 1

    segments = ["It also has a sentence before it.", "This sentence mentions Eqs.", "1-4 and should not be split.", "It also has another sentence after it."]
    merged_segments = merge_segments(segments)
    assert len(merged_segments) == 3

    segments = ["This sentence ends with part an abbreviation that is part of a word material.", "It also has another sentence after it."]
    merged_segments = merge_segments(segments)
    assert len(merged_segments) == 2

    segments = ["This sentence is the last segment and ends with an abbreviation that is part of a word material."]
    merged_segments = merge_segments(segments)
    assert len(merged_segments) == 1